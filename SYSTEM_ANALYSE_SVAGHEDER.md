# ğŸ” Systemanalyse: Svagheder, Flaskehalse & Nedbrudspotentiale

**Dato:** 29. november 2025  
**System:** Jelling Camping StrÃ¸mstyringssystem  
**MÃ¥lere:** 300+ Zigbee-enheder fordelt pÃ¥ 6 omrÃ¥der

---

## ğŸ“Š Systemarkitektur Overblik

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FRONTEND (React)                               â”‚
â”‚                    jelling-power-hub.netlify.app                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SUPABASE CLOUD                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Database   â”‚ â”‚  Edge Functions  â”‚ â”‚     Realtime (WebSocket)   â”‚   â”‚
â”‚  â”‚ (PostgreSQL)â”‚ â”‚  - toggle-power  â”‚ â”‚                            â”‚   â”‚
â”‚  â”‚             â”‚ â”‚  - monitor-usage â”‚ â”‚                            â”‚   â”‚
â”‚  â”‚             â”‚ â”‚  - webhook       â”‚ â”‚                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         NAS (192.168.9.61)                              â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Mosquitto    â”‚â—„â”€â”€â”‚              device-sync.py                  â”‚  â”‚
â”‚  â”‚  MQTT Broker   â”‚   â”‚         (Supabase â†” MQTT sync)              â”‚  â”‚
â”‚  â”‚  Port 1890     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚          â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    6x Zigbee2MQTT Instanser                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â”‚
â”‚  â”‚  â”‚ Area 1   â”‚ â”‚ Area 2   â”‚ â”‚ Area 3   â”‚ â”‚ Area 4   â”‚ ...         â”‚ â”‚
â”‚  â”‚  â”‚ Port 8082â”‚ â”‚ Port 8083â”‚ â”‚ Port 8084â”‚ â”‚ Port 8085â”‚              â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â”‚            â”‚            â”‚            â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚            â”‚            â”‚            â”‚
           â–¼            â–¼            â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Zigbee   â”‚  â”‚ Zigbee   â”‚  â”‚ Zigbee   â”‚  â”‚ Zigbee   â”‚
    â”‚Controllerâ”‚  â”‚Controllerâ”‚  â”‚Controllerâ”‚  â”‚Controllerâ”‚
    â”‚ (Ember)  â”‚  â”‚ (Ember)  â”‚  â”‚ (Ember)  â”‚  â”‚ (Ember)  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚             â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚           ~300 StrÃ¸mmÃ¥lere (Tongou)               â”‚
    â”‚              Zigbee Mesh NetvÃ¦rk                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš¨ KRITISKE SVAGHEDER (Prioritet 1)

### 1. âœ… Z2M Ping Cascade (RETTET I DAG)

**Problem:** NÃ¥r en Zigbee controller mistede forbindelse til mange mÃ¥lere (f.eks. sikringssvigt), ville Z2M blive ved med at pinge ALLE offline mÃ¥lere i det uendelige, hvilket overbelastede hele Zigbee mesh-netvÃ¦rket.

**Konsekvens:** Systemet kunne blive ubrugeligt i timer/dage.

**Status:** âœ… RETTET med `pause_on_backoff_gt: 15` konfiguration.

---

### 2. âš ï¸ MQTT Broker = Single Point of Failure

**Problem:** Mosquitto MQTT broker (port 1890) er en ENKELT instans uden redundans.

**Konsekvens ved nedbrud:**
- ALLE 6 Z2M instanser mister kommunikation
- Ingen strÃ¸mkommandoer kan udfÃ¸res
- device-sync.py fejler
- maaler-opsaetning service fejler

**LÃ¸sning:**
```yaml
# Mulig lÃ¸sning: MQTT Cluster med HiveMQ eller EMQX
# Alternativt: Mosquitto med disk-baseret persistence + automatisk genstart
```

**Anbefaling:**
- [ ] Overvej MQTT broker clustering (HiveMQ/EMQX)
- [ ] ImplementÃ©r health-check med automatisk container genstart
- [ ] TilfÃ¸j monitoring/alerting pÃ¥ MQTT broker status

---

### 3. âš ï¸ NAS = Single Point of Failure

**Problem:** ALLE kritiske services kÃ¸rer pÃ¥ Ã‰N NAS (192.168.9.61):
- Mosquitto MQTT
- 6x Zigbee2MQTT
- device-sync
- Home Assistant
- Telegraf

**Konsekvens ved NAS-nedbrud:**
- Komplet systemnedbrud
- Ingen strÃ¸mstyring mulig
- Data-tab for meter_readings (hvis ikke synkroniseret)

**LÃ¸sning:**
- [ ] Overvej sekundÃ¦r NAS med failover
- [ ] Flyt kritiske services til separat hardware
- [ ] ImplementÃ©r offsite backup af konfigurationsfiler

---

### 4. âš ï¸ Supabase Edge Functions - Ingen Retry Logic

**Fil:** `supabase/functions/toggle-power/index.ts`

**Problem:** NÃ¥r en strÃ¸mkommando sendes, indsÃ¦ttes den i `meter_commands` tabellen. Hvis:
1. Supabase er nede â†’ kommando tabt
2. device-sync ikke kÃ¸rer â†’ kommando aldrig udfÃ¸rt
3. MQTT fejler â†’ kommando sidder fast som "pending"

**NuvÃ¦rende kode (linje 148-158):**
```typescript
// Insert command into meter_commands table
const { error: insertError } = await supabase
  .from('meter_commands')
  .insert({
    meter_id: maaler_id,
    command: 'set_state',
    value: action === 'on' ? 'ON' : 'OFF',
    status: 'pending'
  });
```

**Mangler:**
- [ ] Ingen timeout hÃ¥ndtering for "pending" kommandoer
- [ ] Ingen automatisk retry
- [ ] Ingen feedback til bruger hvis kommando fejler
- [ ] Ingen cleanup af gamle "pending" kommandoer

---

### 5. âš ï¸ device_sync.py - Ingen is_online Opdatering

**Fil:** `device-sync/device_sync.py`

**Problem:** Scriptet synkroniserer enheder til Supabase, men opdaterer IKKE `power_meters.is_online` baseret pÃ¥ Zigbee2MQTT availability status.

**Konsekvens:**
- Frontend viser altid `is_online: true` (default)
- Brugere kan ikke se om en mÃ¥ler faktisk er offline
- Inkonsistens mellem Z2M UI og webapp

**NuvÃ¦rende kode (linje 48-62):**
```python
def upsert_meter_identity(..., availability: str | None, ...):
    payload = {
        "ieee_address": ieee,
        "meter_number": friendly_name,
        "base_topic": base_topic,
        "last_seen": last_seen,
        "availability": availability,  # Gemmes i meter_identity
        "model": model,
        "updated_at": now_iso,
    }
    # ... men power_meters.is_online opdateres ALDRIG!
```

**LÃ¸sning:**
```python
# TilfÃ¸j i upsert_power_meter():
is_online = availability == "online" if availability else True
sb.table("power_meters").upsert({
    "meter_number": friendly_name,
    "mqtt_topic": topic,
    "is_online": is_online,  # <-- TILFÃ˜J DETTE
    "updated_at": now_iso,
}, on_conflict="meter_number").execute()
```

---

## âš¡ FLASKEHALSE (Prioritet 2)

### 6. Zigbee Mesh Kapacitet

**Problem:** Hver Zigbee controller har en teoretisk grÃ¦nse pÃ¥ ~200-400 enheder (afhÃ¦ngig af trafik).

**NuvÃ¦rende setup:**
| OmrÃ¥de | Controller | Estimeret antal |
|--------|------------|-----------------|
| Area 1 | 192.168.0.254:6638 | ~50 |
| Area 2 | 192.168.1.35:6638 | ~50 |
| Area 3 | 192.168.1.9:6638 | ~10 |
| Area 4 | 192.168.1.66:6638 | ~10 |
| Area 5 | 192.168.0.95:6638 | ~10 |
| Area 6 | 192.168.0.60:6638 | ~10 |

**Risiko:** Hvis Ã©t omrÃ¥de vokser til 100+ mÃ¥lere, kan responstid degradere.

**Anbefaling:**
- [ ] Monitorer `messages_per_sec` i Z2M health logs
- [ ] Overvej repeaters hvis signal er svagt
- [ ] Split store omrÃ¥der ved behov

---

### 7. Database Queries i meter_readings

**Problem:** `meter_readings` tabellen vokser konstant (hver mÃ¥ler sender data hvert minut).

**Beregning:**
- 300 mÃ¥lere Ã— 1 reading/min Ã— 60 min Ã— 24 timer = **432.000 rows/dag**
- **13 millioner rows/mÃ¥ned**

**Risiko:**
- Langsomme queries i Dashboard
- Supabase storage limits
- Backup/restore tid

**Anbefaling:**
- [ ] ImplementÃ©r data retention policy (f.eks. slet readings Ã¦ldre end 90 dage)
- [ ] Overvej TimescaleDB til time-series data
- [ ] TilfÃ¸j database indexes pÃ¥ (meter_id, time)

---

### 8. MQTT QoS = 1 (At Least Once)

**Problem:** Flere steder bruges QoS 1, som kan resultere i duplikerede beskeder.

**Fil:** `nas-services/maaler-opsaetning/server.js` (linje 289, 329, 370, 405):
```javascript
mqttClient.publish(topic, payload, { qos: 1 }, (err) => { ... });
```

**Risiko:** Ved netvÃ¦rksproblemer kan en ON/OFF kommando sendes flere gange.

**Anbefaling:**
- [ ] Overvej QoS 2 (Exactly Once) for kritiske kommandoer
- [ ] ImplementÃ©r idempotent kommandohÃ¥ndtering

---

## ğŸ”§ OPERATIONELLE SVAGHEDER (Prioritet 3)

### 9. Manglende Monitoring & Alerting

**Problem:** Ingen automatisk overvÃ¥gning af:
- Container health
- MQTT broker status
- Zigbee controller forbindelse
- Supabase Edge Function fejl
- Database stÃ¸rrelse

**Anbefaling:**
- [ ] ImplementÃ©r Prometheus + Grafana
- [ ] TilfÃ¸j Discord/Slack webhooks for alerts
- [ ] OvervÃ¥g kritiske services med Uptime Kuma

---

### 10. Manglende Backup Strategi

**Problem:** Ingen dokumenteret backup af:
- Z2M configuration.yaml (6 filer)
- Z2M device database
- Mosquitto data
- Home Assistant config

**Konsekvens:** Ved NAS-fejl skal ALT genopbygges manuelt.

**Anbefaling:**
- [ ] Automatisk daglig backup til ekstern lokation
- [ ] Versionskontrol af konfigurationsfiler
- [ ] Test restore-procedure regelmÃ¦ssigt

---

### 11. Hardcoded Credentials

**Problem:** Flere steder har hardcoded MQTT credentials:

**Fil:** `nas-services/maaler-opsaetning/server.js` (linje 13-15):
```javascript
const MQTT_BROKER = 'mqtt://192.168.9.61:1890';
const MQTT_USERNAME = 'homeassistant';
const MQTT_PASSWORD = '7200Grindsted!';  // âš ï¸ Hardcoded!
```

**Risiko:** Sikkerhedsproblem hvis kode deles.

**Anbefaling:**
- [ ] Flyt til miljÃ¸variabler
- [ ] Brug Docker secrets

---

### 12. Ingen Graceful Degradation

**Problem:** Systemet har ingen fallback-mekanismer.

**Eksempler:**
- Hvis Supabase er nede â†’ Frontend crasher
- Hvis MQTT er nede â†’ Ingen strÃ¸mstyring
- Hvis Ã©n Z2M instans er nede â†’ Hele omrÃ¥det er utilgÃ¦ngeligt

**Anbefaling:**
- [ ] ImplementÃ©r offline-mode i frontend
- [ ] Cache seneste status lokalt
- [ ] Vis tydelige fejlbeskeder til brugere

---

## ğŸ“‹ PRIORITERET HANDLINGSPLAN

### Fase 1: Kritiske Fixes (Denne uge)
1. âœ… Z2M availability konfiguration (DONE)
2. â¬œ Opdater device_sync.py til at synkronisere is_online
3. â¬œ TilfÃ¸j cleanup job for gamle "pending" meter_commands

### Fase 2: Stabilitet (NÃ¦ste 2 uger)
4. â¬œ ImplementÃ©r MQTT broker health-check
5. â¬œ TilfÃ¸j automatisk container restart ved fejl
6. â¬œ Opret backup-rutine for Z2M configs

### Fase 3: Skalerbarhed (NÃ¦ste mÃ¥ned)
7. â¬œ ImplementÃ©r data retention for meter_readings
8. â¬œ TilfÃ¸j monitoring dashboard
9. â¬œ DokumentÃ©r disaster recovery procedure

### Fase 4: Sikkerhed (LÃ¸bende)
10. â¬œ Fjern hardcoded credentials
11. â¬œ ImplementÃ©r rate limiting pÃ¥ API endpoints
12. â¬œ TilfÃ¸j audit logging

---

## ğŸ¯ KONKLUSION

Det problem vi rettede i dag (Z2M ping cascade) viser vigtigheden af at analysere systemet grundigt. **En enkelt fejlkonfiguration kunne have gjort hele strÃ¸mstyringssystemet ubrugeligt.**

De mest kritiske omrÃ¥der at adressere:

| Prioritet | Problem | Risiko | Kompleksitet |
|-----------|---------|--------|--------------|
| ğŸ”´ Kritisk | MQTT = SPOF | Totalt nedbrud | Medium |
| ğŸ”´ Kritisk | NAS = SPOF | Totalt nedbrud | HÃ¸j |
| ğŸŸ  HÃ¸j | is_online ikke synkroniseret | Inkonsistent UI | Lav |
| ğŸŸ  HÃ¸j | Ingen retry pÃ¥ kommandoer | Tabte kommandoer | Medium |
| ğŸŸ¡ Medium | Database vÃ¦kst | Langsom performance | Medium |
| ğŸŸ¡ Medium | Ingen monitoring | Sen fejldetektion | Medium |

---

**NÃ¦ste skridt:** GennemgÃ¥ denne analyse og prioriter hvilke punkter der skal adresseres fÃ¸rst.
